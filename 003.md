# 第3回 - はじめての機械学習 - 回帰

## 線形回帰

* 線形回帰はデータ間の線形関係をモデル化する手法
* データ間の差異（残差）を最小化する最適な直線を見つける
* 統計学や機械学習の分野で利用されるアルゴリズム

## プログラミング

1. スコアデータセット（score.csv）をロードする
2. スコアデータセットを理解する - 1変数の要約
3. スコアデータセットを理解する - 2変数の要約
4. 訓練データ、テストデータに分割する
5. 線形回帰で学習する（モデルを作成する）
6. モデルを使って推論する
7. モデルを評価する

---

### 1. スコアデータセット（score.csv）をロードする

```python
import pandas as pd
df = pd.read_csv("score.csv")
df
```

> 事前にGoogle Colab上にscore.csvを配置しておいてください。

### 2. スコアデータセットを理解する - 1変数の要約

```python
import matplotlib.pyplot as plt

print("math mean:", df["math"].mean())
print("math variance:", df["math"].var())
print("math std:", df["math"].std())

plt.hist(df["math"], bins=10)
plt.title('Histogram of math')
plt.xlabel('math')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()
```

### 3. スコアデータセットを理解する - 2変数の要約

```python
print("math science corr:", df[["math", "science"]].corr())

plt.scatter(df["math"], df["science"])
plt.title('Scatter plot of score')
plt.xlabel('math')
plt.ylabel('science')
plt.grid(True)
plt.show()
```

### 4. 訓練データ、テストデータに分割する

```python
from sklearn.model_selection import train_test_split

X = df[["math"]]
y = df["science"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)
```

### 5. 線形回帰で学習する（モデルを作成する）

```python
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)
```

### 6. モデルを使って推論する

```python
from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X_test)
print("R2:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))
```

### 7. モデルを評価する

```python
import numpy as np
# R2
ssr = np.sum((y_test - y_pred)**2)
sst = np.sum((y_test - np.mean(y_test))**2)
print("R2:", 1 - (ssr / sst))
# print(model.score(X_test, y_test))

# MSE
print("MSE:", np.mean((y_test - y_pred)**2))
```
