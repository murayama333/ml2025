# 機械学習 - 分類 -決定木

## 決定木

* 木構造でデータを予測するアルゴリズム
* データの不純度（ジニ係数など）について着目して分岐構造を作る
* 決定木のモデルは「木」の形式で表されるため人間が直感的に理解しやすい

### ジニ係数（ジニ不純度）

* ジニ係数（厳密にはジニ不純度）は、決定木のノード分割の品質を評価する指標
* クラスが完全に混ざっている場合に最大となる
* クラスが完全に分離されている場合に最小（0）となる

$$
I_g(p)=1 - \sum_{i=1}^J p_i^2
$$

#### 計算例 ※先頭のノードの場合

$$
1-((\frac{37}{112})^2 + (\frac{34}{112})^2 + (\frac{41}{112})^2) = 0.665
$$

## サンプルコード

```py
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

iris = load_iris()
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)

model = DecisionTreeClassifier(max_depth=2)
model.fit(x_train, y_train)
model.score(x_test, y_test)

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
plot_tree(model, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)
plt.show()
```

### 実行結果

<img src="img/002.png" width="500px">
