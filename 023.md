# 機械学習の評価指標 - 回帰
* 回帰問題では目的変数が連続値となる
* 予測結果が実測値に近いほど良い（差異を最小限に抑えることで、モデルの予測精度が高まる）
* 主要な評価指標には決定係数、MSE、MAEなどがある

---

## 決定係数：$R^2$

* モデルによって説明されるデータの変動の割合を示し、モデルの適合度を測定する
* 決定係数は0から1までの値を取る
* 決定係数が1に近いほどモデルがデータに良く適合していることを意味する

$$
R^2 = 1 - \frac{S_e^2}{S_y^2}
$$

> $S_y^2$ は目的変数 $y$ の分散、$S_e^2$ は残差の分散です。

---

## 平均絶対値誤差：MAE(Mean Absolute Error)

* 予測値と実際の値の差（誤差）の絶対値の平均
* 誤差の平均的な大きさを直感的に理解しやすい
* 外れ値の影響を受けにくい

$$
MAE = \frac{1}{n}\sum_{i=1}^n |\hat{y_i} - y_i|
$$

---

## 平均二乗平方誤差：MSE(Mean Squared Error)

* 予測値と実際の値の差の二乗平均
* 2乗することで誤差の大きさを強調し、大きな誤差に対しては重いペナルティを課す
* 大きな誤差を出すことのコストが高い場合や、外れ値に対する感度が許容される場合に適している

$$
MSE = \frac{1}{n}\sum_{i=1}^n (\hat{y_i} - y_i)^2 
$$

### 二乗平均平方誤差：RMSE(Root Mean Squared Error)

* MSEの平方根
* MSEは計算過程で2乗しているので、平方根を計算することで単位を解釈しやすくなる
* MSEの特徴である外れ値を大きく評価する特徴は残る

$$
RMSE = \sqrt{MSE}
$$

---

## サンプルコード

```py
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

iris = load_iris()
iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)
target = iris_data["sepal length (cm)"]
data = iris_data[["sepal width (cm)", "petal length (cm)", "petal width (cm)"]]

x_train, x_test, y_train, y_test = train_test_split(data, target, random_state=0)

model = DecisionTreeRegressor(max_depth=3)
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

# 決定係数
r2 = r2_score(y_test, y_pred)
print("R2:", r2)
# MAE
mae = mean_absolute_error(y_test, y_pred)
print("MAE:", mae)
# MSE
mse = mean_squared_error(y_test, y_pred)
print("MSE:", mse)
```

### 実行結果

```py
R2: 0.5975012486448243
MAE: 0.34721813725490197
MSE: 0.18081225071265603
```
