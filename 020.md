# 機械学習アルゴリズム - ランダムフォレスト
* 複数の決定木を組み合わせて高い予測精度を達成するアンサンブル学習の一種
* 各決定木はランダムに選ばれたデータサンプルと特徴量を使用して構築される（過学習を防ぐ）
* 分類や回帰問題に対応し、特徴量の重要度を評価する用途にも使用される

> アンサンブル学習とは、複数の学習アルゴリズムを組み合わせる学習手法です。詳細は次節で取り上げます。

---

## サンプルコード

`iris` データの分類

```py
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

iris = load_iris()
iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)
iris_df['target'] = iris.target

iris = load_iris()
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)

model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)
model.fit(x_train, y_train)
print("acc:", model.score(x_test, y_test))
```

> `RandomForestClassifier` コンストラクタの `n_estimators` 引数で決定木の数を指定します。

### 実行結果

```
acc: 0.9736842105263158
```

### 参考

+ ランダムフォレスト内の決定木の可視化

```py
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(16, 10))
plot_tree(model.estimators_[0], feature_names=iris.feature_names, filled=True, max_depth=5)
plt.show()
```

+ テキストでの可視化

```py
from sklearn.tree import export_text
print(export_text(model.estimators_[0], feature_names=list(iris.feature_names), max_depth=3))
```

+ 特徴量重要度の表示

```py
import pandas as pd

imp = pd.Series(model.feature_importances_, index=iris.feature_names).sort_values()
imp.plot(kind="barh")
plt.show()
```
